{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b089d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0677816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flashtext\n",
      "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: flashtext\n",
      "  Building wheel for flashtext (setup.py): started\n",
      "  Building wheel for flashtext (setup.py): finished with status 'done'\n",
      "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9298 sha256=e0fb0650639298e5ee0d2d6b81f59903c30ac562e8c1ec63ed6d3ca86b966b2d\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\65\\3c\\c7\\44672c5062c16d05760b1eaddbf611d2f6a4b715c6d6777418\n",
      "Successfully built flashtext\n",
      "Installing collected packages: flashtext\n",
      "Successfully installed flashtext-2.7\n"
     ]
    }
   ],
   "source": [
    "#!pip install flashtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecb730e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1d7f2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in d:\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu117/torchvision-0.15.1%2Bcu117-cp39-cp39-win_amd64.whl (4.9 MB)\n",
      "     ---------------------------------------- 4.9/4.9 MB 649.2 kB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu117/torchaudio-2.0.1%2Bcu117-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: sympy in d:\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: networkx in d:\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-2.0.1+cu117 torchvision-0.15.1+cu117\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227d712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline, set_seed\n",
    "import random\n",
    "from flashtext import KeywordProcessor\n",
    "from ast import literal_eval\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac19a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"Must be an extrovert with an innate quality of easily connecting with people.\"\n",
    "sentence2 = \"You're self-motivated and decisive, but willing to make changes with minimal grumbling when the client demands it.\"\n",
    "sentence3 = \"Ideal candidates will be caring, compassinate, adaptable, flexible, commited to high standards of care and possess excelent communication skills both verbal and written.\"\n",
    "sentence4 = \"To be considered for this position you must be energetic, friendly, compassionat and detail oriented.\"\n",
    "sentence5 = \"We are looking for a young and driven candidate who can bring innovation into the organization.\"\n",
    "sentence6 = \"Are you the master of technology and passionate person we are looking for?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a40c5e",
   "metadata": {},
   "source": [
    "# Use BERT for masking arbitrary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d6ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33ef77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36826d8ca98147008769efd93c0fae6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Administrator\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd105e44170464d82b0a28e12f454c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefd45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_random_words(sentence, stop_words, biased_phrase, masked_result=0):\n",
    "    augmented_sentence = sentence\n",
    "    temp = \"\"\n",
    "    for _ in range(5):\n",
    "        not_masked =  True\n",
    "        for word in augmented_sentence.split(\" \"):\n",
    "            random_num = random.random()\n",
    "            if word not in stop_words and word not in biased_phrase and random_num <= 0.2 and not_masked:\n",
    "                temp += \"[MASK] \"\n",
    "                not_masked = False\n",
    "            else:\n",
    "                temp += word + \" \"\n",
    "        if \"[MASK]\" in temp:\n",
    "            result = model(temp)\n",
    "            temp = temp.replace(\"[MASK]\", result[masked_result]['token_str'])\n",
    "        augmented_sentence = temp[:-1]\n",
    "        temp = \"\"\n",
    "            \n",
    "    return augmented_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89dcaf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're self-motivated and decisive, but willing to make changes with minimal grumbling when the client demands it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'very self-motivated and decisive, but able to make decisions with minimal grumbling when the client demands it.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentence2)\n",
    "mask_random_words(sentence2, stop_words, \"decisive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88261637",
   "metadata": {},
   "source": [
    "# Use GPT-2 to finish the sentence for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b91ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86bcc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finish_sentence(sentence, num_generations=5, max_length=25):\n",
    "    generated_sentences = []\n",
    "    temp_generations = generator(sentence, max_length=max_length, num_return_sequences=num_generations)\n",
    "    for generations in temp_generations:\n",
    "        temp = generations['generated_text']\n",
    "        temp = temp.split('.')[0]\n",
    "        temp = temp + '.'\n",
    "        generated_sentences.append(temp)\n",
    "    return generated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c8d0d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['We are looking for a young and driven candidate who has a sense of being a member of a community, having an engaging relationship.',\n",
       " 'We are looking for a young and driven candidate to carry out the best and most complete service in the areas most likely to be.',\n",
       " 'We are looking for a young and driven candidate, willing to address both the needs of current and future generations of workers at the.',\n",
       " 'We are looking for a young and driven candidate, one who has proven himself well and well in several of the last two elections.',\n",
       " 'We are looking for a young and driven candidate who will take our leadership in all sectors of the state and work toward economic prosperity.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finish_sentence(\"We are looking for a young and driven candidate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9962c",
   "metadata": {},
   "source": [
    "# Use flashtext to replace words in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00702d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb737ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45526baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1577b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0753d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
