{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8511c332",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b222c48",
   "metadata": {},
   "source": [
    "## Step 1: initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7f557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ea67c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#initialize the lematizer and stemmer, which will be used later.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#to be used in the cleaning function\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "print(stopwords.words('english'))\n",
    "#print(stopwords.words('chinese'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430196d",
   "metadata": {},
   "source": [
    "## Step 2: Clean the Data\n",
    "The dataset, EMSCAD, is downloaded from Kaggle, the link is here:\n",
    "https://www.kaggle.com/datasets/amruthjithrajvr/recruitment-scam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a7cda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataframe is (17880, 18)\n"
     ]
    }
   ],
   "source": [
    "#load the EMSCAD dataset\n",
    "df = pd.read_csv('./DataSet.csv')\n",
    "print(\"The shape of the dataframe is\",df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291776c",
   "metadata": {},
   "source": [
    "### Get the dataframe for only the Job description column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9a1457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataframe is (17880, 1)\n",
      "Display one Job description sample:\n",
      "\n",
      "<p>Food52, a fast-growing, James Beard Award-winning online food community and crowd-sourced and curated recipe hub, is currently interviewing full- and part-time unpaid interns to work in a small team of editors, executives, and developers in its New York City headquarters.</p>\r\n",
      "<ul>\r\n",
      "<li>Reproducing and/or repackaging existing Food52 content for a number of partner sites, such as Huffington Post, Yahoo, Buzzfeed, and more in their various content management systems</li>\r\n",
      "<li>Researching blogs and websites for the Provisions by Food52 Affiliate Program</li>\r\n",
      "<li>Assisting in day-to-day affiliate program support, such as screening affiliates and assisting in any affiliate inquiries</li>\r\n",
      "<li>Supporting with PR &amp; Events when needed</li>\r\n",
      "<li>Helping with office administrative work, such as filing, mailing, and preparing for meetings</li>\r\n",
      "<li>Working with developers to document bugs and suggest improvements to the site</li>\r\n",
      "<li>Supporting the marketing and executive staff</li>\r\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "df_jd = pd.DataFrame(df['description'])\n",
    "print(\"The shape of the dataframe is\", df_jd.shape) \n",
    "print(\"Display one Job description sample:\\n\") \n",
    "print(df_jd['description'][0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c922e7b",
   "metadata": {},
   "source": [
    "### To display the Job description sample in a more readable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09204a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Food52, a fast-growing, James Beard Award-winning online food community and crowd-sourced and curated recipe hub, is currently interviewing full- and part-time unpaid interns to work in a small team of editors, executives, and developers in its New York City headquarters.</p>\r\n",
       "<ul>\r\n",
       "<li>Reproducing and/or repackaging existing Food52 content for a number of partner sites, such as Huffington Post, Yahoo, Buzzfeed, and more in their various content management systems</li>\r\n",
       "<li>Researching blogs and websites for the Provisions by Food52 Affiliate Program</li>\r\n",
       "<li>Assisting in day-to-day affiliate program support, such as screening affiliates and assisting in any affiliate inquiries</li>\r\n",
       "<li>Supporting with PR &amp; Events when needed</li>\r\n",
       "<li>Helping with office administrative work, such as filing, mailing, and preparing for meetings</li>\r\n",
       "<li>Working with developers to document bugs and suggest improvements to the site</li>\r\n",
       "<li>Supporting the marketing and executive staff</li>\r\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(df_jd['description'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ea9af",
   "metadata": {},
   "source": [
    "### Prepare the cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614351e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the HTML tags\n",
    "def striphtml(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', data)\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    \n",
    "    # remove the HTML tags\n",
    "    text = striphtml(text)\n",
    "    \n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.replace(':', ' ')\n",
    "    text = text.replace('\\'', ' ')\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    # Remove extra spaces from text\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    # Remove stopwords function\n",
    "    # Tokenize : get a list of tokens\n",
    "    stop_words = set(stopwords.words(\"english\")) # nltk.download('stopwords') - this is done at the begining\n",
    "    word_tokens = word_tokenize(text)\n",
    "    text = [word for word in word_tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    text = [lemmatizer.lemmatize(word, pos ='v') for word in text]\n",
    "    \n",
    "    # Stem words\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "70034afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_clean(text):\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    #text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b80cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['organis', 'focu', 'vibrant', 'awesomedo', 'passion', 'custom', 'servic', 'slick', 'type', 'skill', 'mayb', 'account', 'manag', 'think', 'administr', 'cooler', 'polar', 'bear', 'jetski', 'need', 'hear', 'cloud', 'video', 'product', 'servic', 'opper', 'glodal', 'level', 'yeah', 'pretti', 'cool', 'seriou', 'deliv', 'world', 'class', 'product', 'excel', 'custom', 'serviceour', 'rapidli', 'expand', 'busi', 'look', 'talent', 'project', 'manag', 'manag', 'success', 'deliveri', 'video', 'project', 'manag', 'client', 'commun', 'drive', 'product', 'process', 'work', 'coolest', 'brand', 'planet', 'learn', 'global', 'team', 'repres', 'nz', 'huge', 'way', 'enter', 'next', 'growth', 'stage', 'busi', 'grow', 'quickli', 'intern', 'therefor', 'posit', 'burst', 'opportun', 'right', 'person', 'enter', 'busi', 'right', 'time', '90', 'second', 'world', 'cloud', 'video', 'product', 'servic', 'http', '90urlfbe6559afac620a3cd2c22281f7b8d0eef56a73e3d9a311e2f1ca13d081dd630', '90', 'second', 'world', 'cloud', 'video', 'product', 'servic', 'enabl', 'brand', 'agenc', 'get', 'high', 'qualiti', 'onlin', 'video', 'content', 'shoot', 'produc', 'anywher', 'world', 'fast', 'afford', 'manag', 'seamlessli', 'cloud', 'purchas', 'publish', '90', 'second', 'remov', 'hassl', 'cost', 'risk', 'speed', 'issu', 'work', 'regular', 'video', 'product', 'compani', 'manag', 'everi', 'aspect', 'video', 'project', 'beauti', 'onlin', 'experi', 'grow', 'network', '2000', 'rat', 'video', 'profession', '50', 'countri', 'dedic', 'product', 'success', 'team', '5', 'countri', 'guarante', 'video', 'project', 'success', '100', 'easi', 'commiss', 'quick', 'googl', 'adword', 'campaign90', 'second', 'produc', 'almost', '4000', 'video', '30', 'countri', '500', 'global', 'brand', 'includ', 'world', 'largest', 'includ', 'paypal', 'l', 'oreal', 'soni', 'barclay', 'offic', 'auckland', 'london', 'sydney', 'tokyo', 'amp', 'singaporeour', 'auckland', 'offic', 'base', 'right', 'heart', 'wynyard', 'quarter', 'innov', 'precinct', 'gridakl']\n",
      "['client', 'locat', 'houston', 'activ', 'seek', 'experi', 'commiss', 'machineri', 'assist', 'possess', 'strong', 'supervisori', 'skill', 'attent', 'detail', 'strong', 'dedic', 'safeti', 'must', 'ideal', 'candid', 'execut', 'activ', 'compli', 'qualiti', 'requir', 'health', 'environment', 'safeti', 'regul']\n",
      "['compani', 'esri', '–', 'environment', 'system', 'research', 'institut', 'passion', 'improv', 'qualiti', 'life', 'geographi', 'heart', 'everyth', 'esri', '’', 'geograph', 'inform', 'system', 'gi', 'technolog', 'inspir', 'enabl', 'govern', 'univers', 'busi', 'worldwid', 'save', 'money', 'live', 'environ', 'deeper', 'understand', 'chang', 'world', 'around', 'care', 'manag', 'growth', 'zero', 'debt', 'give', 'esri', 'stabil', 'uncommon', 'today', 'volatil', 'busi', 'world', 'privat', 'hold', 'offer', 'except', 'benefit', 'competit', 'salari', '401k', 'profitshar', 'program', 'opportun', 'person', 'profession', 'growth', 'much', 'opportun', 'account', 'execut', 'member', 'sale', 'divis', 'work', 'collabor', 'account', 'team', 'order', 'sell', 'promot', 'adopt', 'esri', '’', 'arcgi', 'platform', 'within', 'organ', 'part', 'account', 'team', 'respons', 'facilit', 'develop', 'execut', 'set', 'strategi', 'defin', 'portfolio', 'account', 'execut', 'strategi', 'util', 'experi', 'enterpris', 'sale', 'help', 'custom', 'leverag', 'geospati', 'inform', 'technolog', 'achiev', 'busi', 'goal', 'specifically…', 'prospect', 'develop', 'opportun', 'partner', 'key', 'stakehold', 'envis', 'develop', 'implement', 'locat', 'strategi', 'organ', 'clearli', 'articul', 'strength', 'valu', 'proposit', 'arcgi', 'platform', 'develop', 'maintain', 'healthi', 'pipelin', 'opportun', 'busi', 'growth', 'demonstr', 'thought', 'understand', 'insight', 'industri', 'knowledg', 'gi', 'appli', 'initi', 'trend', 'trigger', 'understand', 'key', 'busi', 'driver', 'within', 'organ', 'identifi', 'key', 'busi', 'stakehold', 'understand', 'custom', '’', 'budget', 'acquisit', 'process', 'success', 'execut', 'account', 'manag', 'process', 'includ', 'account', 'priorit', 'account', 'resourc', 'account', 'plan', 'success', 'execut', 'sale', 'process', 'opportun', 'leverag', 'lead', 'account', 'team', 'consist', 'sale', 'crossdivision', 'resourc', 'defin', 'execut', 'account', 'strategi', 'effect', 'util', 'leverag', 'crm', 'manag', 'opportun', 'drive', 'buy', 'process', 'pursu', 'profession', 'person', 'develop', 'ensur', 'competit', 'knowledg', 'real', 'estat', 'industri', 'leverag', 'social', 'media', 'success', 'prospect', 'build', 'profession', 'network', 'particip', 'trade', 'show', 'workshop', 'seminar', 'requir', 'support', 'visual', 'stori', 'tell', 'effect', 'whiteboard', 'session', 'resourc', 'take', 'initi', 'resolv', 'issu']\n",
      "['job', 'titl', 'item', 'review', 'manag', 'locat', 'fort', 'worth', 'tx', 'depart', 'item', 'review', 'report', 'vp', 'oper', 'gener', 'descript', 'respons', 'overal', 'aspect', 'item', 'review', 'oper', 'personnel', 'hire', 'qualiti', 'control', 'process', 'workflow', 'monitor', 'track', 'account', 'staff', 'regard', 'product', 'standard', 'depart', 'expect', 'duti', 'respons', 'overse', 'compani', '’', 'item', 'review', 'depart', 'oper', 'respons', 'encourag', 'reinforc', 'compani', 'cultur', 'develop', 'process', 'better', 'depart', 'implement', 'new', 'proceduresprotocol', 'work', 'custom', 'servic', 'elev', 'issu', 'provid', 'call', 'implement', 'audit', 'polici', 'conjunct', 'polici', 'payment', 'integr', 'depart', 'monitor', 'qualityand', 'qualiti', 'control', 'result', 'depart', 'respons', 'ensur', 'overal', 'metric', 'complianc', 'manag', 'client', 'expect', 'respons', 'human', 'resourc', 'matter', 'directli', 'relat', 'depart', 'supervis', 'ie', 'interview', 'hire', 'train', 'annual', 'evalu', 'electron', 'time', 'card', 'address', 'personnel', 'issu', 'may', 'createreview', 'daili', 'weekli', 'monthli', 'report', 'invoic', 'log', 'expens', 'addit', 'dutiesrespons', 'assign', 'compli', 'safeti', 'rulesregul', 'conjunct', 'injuri', 'ill', 'prevent', 'program', '“', 'iipp', '”', 'well', 'maintain', 'hipaa', 'complianc', 'occasion', 'interact', 'custom']\n"
     ]
    }
   ],
   "source": [
    "# for now, I only used some of the examples (df_jd['description'][1:100]), due to the computing capability.\n",
    "\n",
    "df_jd_sentence = pd.DataFrame()\n",
    "\n",
    "for index, sentence in df_jd['description'][1:5].iteritems(): \n",
    "    #df_jd_sentence.add(clean(sentence))\n",
    "    print(clean(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5f889",
   "metadata": {},
   "source": [
    "##  For the purpose of demonstration, I did a cleaning process step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87d061b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Food52, a fast-growing, James Beard Award-winning online food community and crowd-sourced and curated recipe hub, is currently interviewing full- and part-time unpaid interns to work in a small team of editors, executives, and developers in its New York City headquarters.</p>\r\n",
      "<ul>\r\n",
      "<li>Reproducing and/or repackaging existing Food52 content for a number of partner sites, such as Huffington Post, Yahoo, Buzzfeed, and more in their various content management systems</li>\r\n",
      "<li>Researching blogs and websites for the Provisions by Food52 Affiliate Program</li>\r\n",
      "<li>Assisting in day-to-day affiliate program support, such as screening affiliates and assisting in any affiliate inquiries</li>\r\n",
      "<li>Supporting with PR &amp; Events when needed</li>\r\n",
      "<li>Helping with office administrative work, such as filing, mailing, and preparing for meetings</li>\r\n",
      "<li>Working with developers to document bugs and suggest improvements to the site</li>\r\n",
      "<li>Supporting the marketing and executive staff</li>\r\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "# define new variables, \"text_jd\" and \"text_jd_without_stopwords\", which will only be used here for demonstration\n",
    "# and only use one job description as example.\n",
    "text_jd = df_jd['description'][0]\n",
    "print(text_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8e44ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food52, a fast-growing, James Beard Award-winning online food community and crowd-sourced and curated recipe hub, is currently interviewing full- and part-time unpaid interns to work in a small team of editors, executives, and developers in its New York City headquarters.\r\n",
      "\r\n",
      "Reproducing and/or repackaging existing Food52 content for a number of partner sites, such as Huffington Post, Yahoo, Buzzfeed, and more in their various content management systems\r\n",
      "Researching blogs and websites for the Provisions by Food52 Affiliate Program\r\n",
      "Assisting in day-to-day affiliate program support, such as screening affiliates and assisting in any affiliate inquiries\r\n",
      "Supporting with PR &amp; Events when needed\r\n",
      "Helping with office administrative work, such as filing, mailing, and preparing for meetings\r\n",
      "Working with developers to document bugs and suggest improvements to the site\r\n",
      "Supporting the marketing and executive staff\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove the HTML tags\n",
    "text_jd = striphtml(text_jd)\n",
    "print(text_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89faedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food52, a fast-growing, james beard award-winning online food community and crowd-sourced and curated recipe hub, is currently interviewing full- and part-time unpaid interns to work in a small team of editors, executives, and developers in its new york city headquarters.\r\n",
      "\r\n",
      "reproducing and/or repackaging existing food52 content for a number of partner sites, such as huffington post, yahoo, buzzfeed, and more in their various content management systems\r\n",
      "researching blogs and websites for the provisions by food52 affiliate program\r\n",
      "assisting in day-to-day affiliate program support, such as screening affiliates and assisting in any affiliate inquiries\r\n",
      "supporting with pr &amp; events when needed\r\n",
      "helping with office administrative work, such as filing, mailing, and preparing for meetings\r\n",
      "working with developers to document bugs and suggest improvements to the site\r\n",
      "supporting the marketing and executive staff\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lowercase text\n",
    "text_jd = text_jd.lower()\n",
    "print(text_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f01101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food52 a fastgrowing james beard awardwinning online food community and crowdsourced and curated recipe hub is currently interviewing full and parttime unpaid interns to work in a small team of editors executives and developers in its new york city headquarters\r\n",
      "\r\n",
      "reproducing andor repackaging existing food52 content for a number of partner sites such as huffington post yahoo buzzfeed and more in their various content management systems\r\n",
      "researching blogs and websites for the provisions by food52 affiliate program\r\n",
      "assisting in daytoday affiliate program support such as screening affiliates and assisting in any affiliate inquiries\r\n",
      "supporting with pr amp events when needed\r\n",
      "helping with office administrative work such as filing mailing and preparing for meetings\r\n",
      "working with developers to document bugs and suggest improvements to the site\r\n",
      "supporting the marketing and executive staff\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove ':', '\\', and punctuation\n",
    "text_jd = text_jd.replace(':', ' ')\n",
    "text_jd = text_jd.replace('\\'', ' ')\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "text_jd = text_jd.translate(translator)\n",
    "print(text_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb47f8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food52 a fastgrowing james beard awardwinning online food community and crowdsourced and curated recipe hub is currently interviewing full and parttime unpaid interns to work in a small team of editors executives and developers in its new york city headquarters reproducing andor repackaging existing food52 content for a number of partner sites such as huffington post yahoo buzzfeed and more in their various content management systems researching blogs and websites for the provisions by food52 affiliate program assisting in daytoday affiliate program support such as screening affiliates and assisting in any affiliate inquiries supporting with pr amp events when needed helping with office administrative work such as filing mailing and preparing for meetings working with developers to document bugs and suggest improvements to the site supporting the marketing and executive staff\n"
     ]
    }
   ],
   "source": [
    "# Remove extra spaces from text\n",
    "text_jd = \" \".join(text_jd.split())\n",
    "print(text_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caa4abdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"hasn't\", \"couldn't\", 'him', 've', 'being', 'didn', 'here', 'will', 'herself', 'shouldn', 'shan', \"aren't\", 'each', 'don', 'some', 'same', 'all', \"you'd\", 'you', 'hasn', 'we', \"you'll\", 'can', 'needn', \"shouldn't\", 'd', 'a', 'of', 'doesn', \"doesn't\", 'out', 's', 'his', \"she's\", 'themselves', 'isn', 'only', 'why', 'were', 'ma', 'over', 'where', 'other', \"should've\", 'my', 'after', 'such', 'll', 'the', 'm', 'at', 'or', 'few', 'i', 'she', 'down', 'won', 'once', 'weren', 'which', 'be', 'how', \"that'll\", 'very', \"you're\", 'he', 'by', 'because', \"don't\", 'these', 'against', 'own', 'then', 'but', 'if', 'to', 'those', 'both', 'our', 'mightn', 'when', 'until', 'aren', 'me', 'into', 'have', 'yours', 'before', 'through', \"isn't\", 'wouldn', 'hers', 'what', 'ain', 'their', 'any', 'o', 'wasn', 'had', \"wouldn't\", 'that', 'her', 'is', \"didn't\", 'couldn', 'above', \"it's\", 'theirs', 'on', 'about', 'off', 'do', 'it', 'ours', 'just', 'further', \"mustn't\", 'too', 'this', 'them', 'below', 'itself', 'there', 'has', \"won't\", 'am', 'from', 'most', \"you've\", 'haven', 'in', 'did', 'are', 'having', 'your', \"shan't\", 'not', 'they', \"wasn't\", 'should', 'who', 'does', 'while', \"hadn't\", 'its', 'hadn', 'whom', 'yourselves', 'doing', 'as', 'more', 'himself', 'was', 'than', 'ourselves', 'during', 'with', 'yourself', 'and', 'for', \"mightn't\", 'between', 'under', 'nor', \"haven't\", 'myself', 'now', \"needn't\", 'mustn', 'so', 'an', \"weren't\", 'up', 't', 'again', 'no', 'y', 're', 'been'}\n"
     ]
    }
   ],
   "source": [
    "# set stopwords \n",
    "stop_words = set(stopwords.words(\"english\")) # nltk.download('stopwords') - this is done at the begining\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d670007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food52', 'fastgrowing', 'james', 'beard', 'awardwinning', 'online', 'food', 'community', 'crowdsourced', 'curated', 'recipe', 'hub', 'currently', 'interviewing', 'full', 'parttime', 'unpaid', 'interns', 'work', 'small', 'team', 'editors', 'executives', 'developers', 'new', 'york', 'city', 'headquarters', 'reproducing', 'andor', 'repackaging', 'existing', 'food52', 'content', 'number', 'partner', 'sites', 'huffington', 'post', 'yahoo', 'buzzfeed', 'various', 'content', 'management', 'systems', 'researching', 'blogs', 'websites', 'provisions', 'food52', 'affiliate', 'program', 'assisting', 'daytoday', 'affiliate', 'program', 'support', 'screening', 'affiliates', 'assisting', 'affiliate', 'inquiries', 'supporting', 'pr', 'amp', 'events', 'needed', 'helping', 'office', 'administrative', 'work', 'filing', 'mailing', 'preparing', 'meetings', 'working', 'developers', 'document', 'bugs', 'suggest', 'improvements', 'site', 'supporting', 'marketing', 'executive', 'staff']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize : get a list of tokens\n",
    "# Remove stop words\n",
    "word_tokens = word_tokenize(text_jd)\n",
    "text_jd_without_stopwords = [word for word in word_tokens if word not in stop_words]\n",
    "print(text_jd_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2140d58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food52', 'fastgrowing', 'jam', 'beard', 'awardwinning', 'online', 'food', 'community', 'crowdsourced', 'curated', 'recipe', 'hub', 'currently', 'interview', 'full', 'parttime', 'unpaid', 'intern', 'work', 'small', 'team', 'editors', 'executives', 'developers', 'new', 'york', 'city', 'headquarter', 'reproduce', 'andor', 'repackaging', 'exist', 'food52', 'content', 'number', 'partner', 'sit', 'huffington', 'post', 'yahoo', 'buzzfeed', 'various', 'content', 'management', 'systems', 'research', 'blog', 'websites', 'provision', 'food52', 'affiliate', 'program', 'assist', 'daytoday', 'affiliate', 'program', 'support', 'screen', 'affiliate', 'assist', 'affiliate', 'inquiries', 'support', 'pr', 'amp', 'events', 'need', 'help', 'office', 'administrative', 'work', 'file', 'mail', 'prepare', 'meet', 'work', 'developers', 'document', 'bug', 'suggest', 'improvements', 'site', 'support', 'market', 'executive', 'staff']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize words\n",
    "text_jd_without_stopwords = [lemmatizer.lemmatize(word, pos ='v') for word in text_jd_without_stopwords]\n",
    "print(text_jd_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "880c0460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food52', 'fastgrow', 'jam', 'beard', 'awardwin', 'onlin', 'food', 'commun', 'crowdsourc', 'curat', 'recip', 'hub', 'current', 'interview', 'full', 'parttim', 'unpaid', 'intern', 'work', 'small', 'team', 'editor', 'execut', 'develop', 'new', 'york', 'citi', 'headquart', 'reproduc', 'andor', 'repackag', 'exist', 'food52', 'content', 'number', 'partner', 'sit', 'huffington', 'post', 'yahoo', 'buzzfe', 'variou', 'content', 'manag', 'system', 'research', 'blog', 'websit', 'provis', 'food52', 'affili', 'program', 'assist', 'daytoday', 'affili', 'program', 'support', 'screen', 'affili', 'assist', 'affili', 'inquiri', 'support', 'pr', 'amp', 'event', 'need', 'help', 'offic', 'administr', 'work', 'file', 'mail', 'prepar', 'meet', 'work', 'develop', 'document', 'bug', 'suggest', 'improv', 'site', 'support', 'market', 'execut', 'staff']\n"
     ]
    }
   ],
   "source": [
    "# Stem words \n",
    "text_jd_without_stopwords = [stemmer.stem(word) for word in text_jd_without_stopwords]\n",
    "print(text_jd_without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596fe3e",
   "metadata": {},
   "source": [
    "# Step 2: preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dc14caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 2)\n",
      "  Biased Words or Phrases Masculine/Feminine Bias\n",
      "0                  active          Masculine Bias\n",
      "1             adventurous          Masculine Bias\n",
      "2                 aggress          Masculine Bias\n",
      "3                 ambitio          Masculine Bias\n",
      "4                   analy          Masculine Bias\n",
      "Masculine Bias    95\n",
      "Feminine Bias     64\n",
      "Name: Masculine/Feminine Bias, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get the list of biased words or phrases\n",
    "df_biased_words = pd.read_excel(\"./bias_words.xlsx\")\n",
    "print(df_biased_words.shape)\n",
    "print(df_biased_words.head())\n",
    "print(df_biased_words['Masculine/Feminine Bias'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3941048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 2)\n",
      "Biased Words or Phrases    False\n",
      "Masculine/Feminine Bias    False\n",
      "dtype: bool\n",
      "  Biased Words or Phrases Masculine/Feminine Bias\n",
      "0                  active          Masculine Bias\n",
      "1             adventurous          Masculine Bias\n",
      "2                 aggress          Masculine Bias\n",
      "3                 ambitio          Masculine Bias\n",
      "4                   analy          Masculine Bias\n",
      "Masculine Bias    81\n",
      "Feminine Bias     56\n",
      "Name: Masculine/Feminine Bias, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# exclude generic he/she and dupulicated words in df_biased_words\n",
    "words_to_exclude = ['she', 'her', 'hers', 'herself', 'he', 'himself', 'him', 'his']\n",
    "df_biased_words = df_biased_words[~df_biased_words['Biased Words or Phrases'].isin(words_to_exclude)]\n",
    "df_biased_words = df_biased_words.drop_duplicates()\n",
    "\n",
    "print(df_biased_words.shape)\n",
    "print(df_biased_words.isna().any())# check if there's any empty cells\n",
    "print(df_biased_words.head())\n",
    "print(df_biased_words['Masculine/Feminine Bias'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3248f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of male_words and female words\n",
    "male_words = (df_biased_words.loc[df_biased_words['Masculine/Feminine Bias'] == 'Masculine Bias'])['Biased Words or Phrases'].values\n",
    "female_words = (df_biased_words.loc[df_biased_words['Masculine/Feminine Bias'] == 'Feminine Bias'])['Biased Words or Phrases'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb6ff917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['active' 'adventurous' 'aggress' 'ambitio' 'analy' 'assert' 'athlet'\n",
      " 'autonom' 'boast' 'challeng' 'compet' 'confident' 'courag' 'decide'\n",
      " 'decisive' 'decision' 'determin' 'dominant' 'domina' 'force' 'greedy'\n",
      " 'headstrong' 'hierarch' 'hostil' 'implusive' 'independen' 'individual'\n",
      " 'intellect' 'lead' 'logic' 'masculine' 'objective' 'opinion' 'outspoken'\n",
      " 'persist' 'principle' 'reckless' 'stubborn' 'superior' 'self-confiden'\n",
      " 'self-sufficien' 'self-relian' 'manmade' 'chairman' 'son' 'fireman'\n",
      " 'freshman' 'man' 'mankind' 'manpower' 'boyfriend' 'husband' 'policeman'\n",
      " 'walter' 'brother' 'spokesman' 'upperclassman' 'gentleman' 'alumnus'\n",
      " 'alumni' 'man up' 'Mr.' 'man-made' 'the common man' 'mailman' 'steward'\n",
      " 'actor' 'congressman' 'acts as a leader' 'aggressive' 'ambitious'\n",
      " 'analytical' 'assertive' 'athletic' 'competitive' 'defends own beliefs'\n",
      " 'forceful' 'has leadership abilities' 'independent' 'individualistic'\n",
      " 'makes decisions easily']\n"
     ]
    }
   ],
   "source": [
    "print(male_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7388b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affectionate' 'child' 'cheer' 'commit' 'communal' 'compassion' 'connect'\n",
      " 'considerate' 'cooperat' 'depend' 'emotiona' 'empath' 'feminine'\n",
      " 'flatterable' 'gentle' 'honest' 'interpersonal' 'interdependen'\n",
      " 'interpersona' 'kind' 'kinship' 'loyal' 'modesty' 'nag' 'nurtur'\n",
      " 'pleasant' 'polite' 'quiet' 'respon' 'sensitiv' 'submissive' 'support'\n",
      " 'sympath' 'tender' 'together' 'trust' 'understand' 'warm' 'whin' 'yield'\n",
      " 'daughter' 'wife' 'girlfriend' 'waitress' 'sister' 'ladies' 'alumna'\n",
      " 'alumnae' 'hysterical' 'shrill' 'nagging' 'Mrs.' 'Miss.' 'Ms.'\n",
      " 'stewardess' 'actress']\n"
     ]
    }
   ],
   "source": [
    "print(female_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd6c27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start to test for checking male and female worsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56def600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bec6b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'sentences': ['Must be an extrovert with an innate quality of easily connecting with people.', \n",
    "                      'You are self-motivated and decisive, but willing to make changes with minimal grumbling when the client demands it.', \n",
    "                      'We are looking for a young and driven candidate who can bring innovation into the organization.']}\n",
    "\n",
    "df_test_sentence = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a7c56f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Must be an extrovert with an innate quality of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are self-motivated and decisive, but willi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are looking for a young and driven candidat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences\n",
       "0  Must be an extrovert with an innate quality of...\n",
       "1  You are self-motivated and decisive, but willi...\n",
       "2  We are looking for a young and driven candidat..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ca7d0",
   "metadata": {},
   "source": [
    "## the following block is to fine out  in each setnece if there is any male or female words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2ca4117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df_check_result = pd.DataFrame()\n",
    "\n",
    "for index, sentence in df_test_sentence.iterrows():\n",
    "    temp_sentence = sentence['sentences']\n",
    "    tokenized_sentence = clean(temp_sentence)\n",
    "    \n",
    "    # there will be columns named 'category', 'word_in_sentences', and 'biased_term' in 'df_check_result' \n",
    "    category = 'neutral' \n",
    "    word_in_sentence = 'None' # \n",
    "    word = 'None' # \n",
    "    \n",
    "    # check for male words, and them put the outcome to \n",
    "    for male_word in male_words:\n",
    "        if re.search(r\"\\b{}\\b\".format(male_word), temp_sentence.lower().strip()): # search for 'male_word' in 'temp_sentence' using RE\n",
    "            # set output if 'male_word' is found\n",
    "            category = 'masculine'\n",
    "            word_in_sentence = male_word\n",
    "            word = male_word\n",
    "            #when there is no male word in the temp_sentence \n",
    "        else:\n",
    "            for token in tokenized_sentence:\n",
    "                if len(male_word) > 3:\n",
    "                    if simple_clean(male_word) == token[:len(male_word)]: # check if the male_word is found at the beginning of the token\n",
    "                        category = 'masculine'\n",
    "                        word_in_sentence = token\n",
    "                        word = male_word\n",
    "                    elif simple_clean(male_word) == token[-len(male_word):]: # check if the male_word is found at the end of the token\n",
    "                        category = 'masculine'\n",
    "                        word_in_sentence = token\n",
    "                        word = male_word\n",
    "            \n",
    "    if category == 'masculine': # put the outcome in a dict, then append them to 'df_check_result'\n",
    "        dict = {'sentence': temp_sentence,\n",
    "                'word_in_Sentence': word_in_sentence,\n",
    "                'biased_term': word,\n",
    "                'category': category\n",
    "               }\n",
    "        #df_check_result = df_check_result.append(dict, ignore_index = True)\n",
    "        df_check_result = pd.concat([df_check_result, pd.DataFrame([dict])], ignore_index=True)\n",
    "\n",
    "        \n",
    "        \n",
    "    # the completely same process for checking for female words\n",
    "    for female_word in female_words:\n",
    "        if re.search(r\"\\b{}\\b\".format(female_word), temp_sentence.lower().strip()):\n",
    "            category = 'feminine'\n",
    "            word_in_sentence = female_word\n",
    "            word = female_word\n",
    "        else:\n",
    "            for token in tokenized_sentence:\n",
    "                if len(female_word) > 3:\n",
    "                    if simple_clean(female_word) == token[:len(female_word)]:\n",
    "                        category = 'feminine'\n",
    "                        word_in_sentence = token\n",
    "                        word = female_word\n",
    "                    elif simple_clean(female_word) == token[-len(female_word):]:\n",
    "                        category = 'feminine'\n",
    "                        word_in_sentence = token\n",
    "                        word = female_word\n",
    "                    \n",
    "    if category == 'feminine':\n",
    "        dict = {'sentence': temp_sentence,\n",
    "                'word_in_Sentence': word_in_sentence,\n",
    "                'biased_term': word,\n",
    "                'category': category\n",
    "               }\n",
    "        #df_check_result = df_check_result.append(dict, ignore_index = True)\n",
    "        df_check_result = pd.concat([df_check_result, pd.DataFrame([dict])], ignore_index=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # This is to roughly monitor how many lines/sentences have been proceeded when running this block of code\n",
    "    if index%10000 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "765133f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_in_Sentence</th>\n",
       "      <th>biased_term</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Must be an extrovert with an innate quality of...</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "      <td>feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are self-motivated and decisive, but willi...</td>\n",
       "      <td>decisive</td>\n",
       "      <td>decisive</td>\n",
       "      <td>masculine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence word_in_Sentence  \\\n",
       "0  Must be an extrovert with an innate quality of...          connect   \n",
       "1  You are self-motivated and decisive, but willi...         decisive   \n",
       "\n",
       "  biased_term   category  \n",
       "0     connect   feminine  \n",
       "1    decisive  masculine  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the reult frome checking male/female words are now put into 'df_check_result'\n",
    "df_check_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92971c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
