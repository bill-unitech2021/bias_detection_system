{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8511c332",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b222c48",
   "metadata": {},
   "source": [
    "## Step 1: initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7f557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ea67c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/bill/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/bill/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/bill/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/bill/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#initialize the lematizer and stemmer, which will be used later.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#to be used in the cleaning function\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "print(stopwords.words('english'))\n",
    "#print(stopwords.words('chinese'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430196d",
   "metadata": {},
   "source": [
    "## Step 2: Clean the Data\n",
    "The dataset, EMSCAD, is downloaded from Kaggle, the link is here:\n",
    "https://www.kaggle.com/datasets/amruthjithrajvr/recruitment-scam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a7cda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataframe is (17880, 18)\n"
     ]
    }
   ],
   "source": [
    "#load the EMSCAD dataset\n",
    "df = pd.read_csv('./DataSet.csv')\n",
    "print(\"The shape of the dataframe is\",df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291776c",
   "metadata": {},
   "source": [
    "### Get the dataframe for only the Job description column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9a1457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataframe is (17880, 1)\n",
      "Display one Job description sample:\n",
      "\n",
      "<p>Food52, a fast-growing, James Beard Award-winning online food community and crowd-sourced and curated recipe hub, is currently interviewing full- and part-time unpaid interns to work in a small team of editors, executives, and developers in its New York City headquarters.</p>\r\n",
      "<ul>\r\n",
      "<li>Reproducing and/or repackaging existing Food52 content for a number of partner sites, such as Huffington Post, Yahoo, Buzzfeed, and more in their various content management systems</li>\r\n",
      "<li>Researching blogs and websites for the Provisions by Food52 Affiliate Program</li>\r\n",
      "<li>Assisting in day-to-day affiliate program support, such as screening affiliates and assisting in any affiliate inquiries</li>\r\n",
      "<li>Supporting with PR &amp; Events when needed</li>\r\n",
      "<li>Helping with office administrative work, such as filing, mailing, and preparing for meetings</li>\r\n",
      "<li>Working with developers to document bugs and suggest improvements to the site</li>\r\n",
      "<li>Supporting the marketing and executive staff</li>\r\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "df_jd = pd.DataFrame(df['description'])\n",
    "print(\"The shape of the dataframe is\", df_jd.shape) \n",
    "print(\"Display one Job description sample:\\n\") \n",
    "print(df_jd['description'][0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c922e7b",
   "metadata": {},
   "source": [
    "### To display the Job description sample in a more readable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09204a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Food52, a fast-growing, James Beard Award-winning online food community and crowd-sourced and curated recipe hub, is currently interviewing full- and part-time unpaid interns to work in a small team of editors, executives, and developers in its New York City headquarters.</p>\r\n",
       "<ul>\r\n",
       "<li>Reproducing and/or repackaging existing Food52 content for a number of partner sites, such as Huffington Post, Yahoo, Buzzfeed, and more in their various content management systems</li>\r\n",
       "<li>Researching blogs and websites for the Provisions by Food52 Affiliate Program</li>\r\n",
       "<li>Assisting in day-to-day affiliate program support, such as screening affiliates and assisting in any affiliate inquiries</li>\r\n",
       "<li>Supporting with PR &amp; Events when needed</li>\r\n",
       "<li>Helping with office administrative work, such as filing, mailing, and preparing for meetings</li>\r\n",
       "<li>Working with developers to document bugs and suggest improvements to the site</li>\r\n",
       "<li>Supporting the marketing and executive staff</li>\r\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(df_jd['description'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ea9af",
   "metadata": {},
   "source": [
    "### Prepare the cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614351e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the HTML tags\n",
    "def striphtml(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', data)\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    \n",
    "    # remove the HTML tags\n",
    "    text = striphtml(text)\n",
    "    \n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.replace(':', ' ')\n",
    "    text = text.replace('\\'', ' ')\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    # Remove extra spaces from text\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    # Remove stopwords function\n",
    "    # Tokenize : get a list of tokens\n",
    "    stop_words = set(stopwords.words(\"english\")) # nltk.download('stopwords') - this is done at the begining\n",
    "    word_tokens = word_tokenize(text)\n",
    "    text = [word for word in word_tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    text = [lemmatizer.lemmatize(word, pos ='v') for word in text]\n",
    "    \n",
    "    # Stem words\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc682dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_clean(text):\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    #text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b80cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['organis', 'focu', 'vibrant', 'awesomedo', 'passion', 'custom', 'servic', 'slick', 'type', 'skill', 'mayb', 'account', 'manag', 'think', 'administr', 'cooler', 'polar', 'bear', 'jetski', 'need', 'hear', 'cloud', 'video', 'product', 'servic', 'opper', 'glodal', 'level', 'yeah', 'pretti', 'cool', 'seriou', 'deliv', 'world', 'class', 'product', 'excel', 'custom', 'serviceour', 'rapidli', 'expand', 'busi', 'look', 'talent', 'project', 'manag', 'manag', 'success', 'deliveri', 'video', 'project', 'manag', 'client', 'commun', 'drive', 'product', 'process', 'work', 'coolest', 'brand', 'planet', 'learn', 'global', 'team', 'repres', 'nz', 'huge', 'way', 'enter', 'next', 'growth', 'stage', 'busi', 'grow', 'quickli', 'intern', 'therefor', 'posit', 'burst', 'opportun', 'right', 'person', 'enter', 'busi', 'right', 'time', '90', 'second', 'world', 'cloud', 'video', 'product', 'servic', 'http', '90urlfbe6559afac620a3cd2c22281f7b8d0eef56a73e3d9a311e2f1ca13d081dd630', '90', 'second', 'world', 'cloud', 'video', 'product', 'servic', 'enabl', 'brand', 'agenc', 'get', 'high', 'qualiti', 'onlin', 'video', 'content', 'shoot', 'produc', 'anywher', 'world', 'fast', 'afford', 'manag', 'seamlessli', 'cloud', 'purchas', 'publish', '90', 'second', 'remov', 'hassl', 'cost', 'risk', 'speed', 'issu', 'work', 'regular', 'video', 'product', 'compani', 'manag', 'everi', 'aspect', 'video', 'project', 'beauti', 'onlin', 'experi', 'grow', 'network', '2000', 'rat', 'video', 'profession', '50', 'countri', 'dedic', 'product', 'success', 'team', '5', 'countri', 'guarante', 'video', 'project', 'success', '100', 'easi', 'commiss', 'quick', 'googl', 'adword', 'campaign90', 'second', 'produc', 'almost', '4000', 'video', '30', 'countri', '500', 'global', 'brand', 'includ', 'world', 'largest', 'includ', 'paypal', 'l', 'oreal', 'soni', 'barclay', 'offic', 'auckland', 'london', 'sydney', 'tokyo', 'amp', 'singaporeour', 'auckland', 'offic', 'base', 'right', 'heart', 'wynyard', 'quarter', 'innov', 'precinct', 'gridakl']\n"
     ]
    }
   ],
   "source": [
    "# for now, I only used some of the examples (df_jd['description'][1:100]), due to the computing capability.\n",
    "\n",
    "for index, sentence in df_jd['description'][1:2].iteritems(): \n",
    "    #df_jd_sentence.add(clean(sentence))\n",
    "    print(clean(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596fe3e",
   "metadata": {},
   "source": [
    "# Step 2: preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc14caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 2)\n",
      "  Biased Words or Phrases Masculine/Feminine Bias\n",
      "0                  active          Masculine Bias\n",
      "1             adventurous          Masculine Bias\n",
      "2                 aggress          Masculine Bias\n",
      "3                 ambitio          Masculine Bias\n",
      "4                   analy          Masculine Bias\n",
      "Masculine Bias    95\n",
      "Feminine Bias     64\n",
      "Name: Masculine/Feminine Bias, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get the list of biased words or phrases\n",
    "df_biased_words = pd.read_excel(\"./bias_words.xlsx\")\n",
    "print(df_biased_words.shape)\n",
    "print(df_biased_words.head())\n",
    "print(df_biased_words['Masculine/Feminine Bias'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3941048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 2)\n",
      "Biased Words or Phrases    False\n",
      "Masculine/Feminine Bias    False\n",
      "dtype: bool\n",
      "  Biased Words or Phrases Masculine/Feminine Bias\n",
      "0                  active          Masculine Bias\n",
      "1             adventurous          Masculine Bias\n",
      "2                 aggress          Masculine Bias\n",
      "3                 ambitio          Masculine Bias\n",
      "4                   analy          Masculine Bias\n",
      "Masculine Bias    81\n",
      "Feminine Bias     56\n",
      "Name: Masculine/Feminine Bias, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# exclude generic he/she and dupulicated words in df_biased_words\n",
    "words_to_exclude = ['she', 'her', 'hers', 'herself', 'he', 'himself', 'him', 'his']\n",
    "df_biased_words = df_biased_words[~df_biased_words['Biased Words or Phrases'].isin(words_to_exclude)]\n",
    "df_biased_words = df_biased_words.drop_duplicates()\n",
    "\n",
    "print(df_biased_words.shape)\n",
    "print(df_biased_words.isna().any())# check if there's any empty cells\n",
    "print(df_biased_words.head())\n",
    "print(df_biased_words['Masculine/Feminine Bias'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3248f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of male_words and female words\n",
    "male_words = (df_biased_words.loc[df_biased_words['Masculine/Feminine Bias'] == 'Masculine Bias'])['Biased Words or Phrases'].values\n",
    "female_words = (df_biased_words.loc[df_biased_words['Masculine/Feminine Bias'] == 'Feminine Bias'])['Biased Words or Phrases'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb6ff917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['active' 'adventurous' 'aggress' 'ambitio' 'analy' 'assert' 'athlet'\n",
      " 'autonom' 'boast' 'challeng' 'compet' 'confident' 'courag' 'decide'\n",
      " 'decisive' 'decision' 'determin' 'dominant' 'domina' 'force' 'greedy'\n",
      " 'headstrong' 'hierarch' 'hostil' 'implusive' 'independen' 'individual'\n",
      " 'intellect' 'lead' 'logic' 'masculine' 'objective' 'opinion' 'outspoken'\n",
      " 'persist' 'principle' 'reckless' 'stubborn' 'superior' 'self-confiden'\n",
      " 'self-sufficien' 'self-relian' 'manmade' 'chairman' 'son' 'fireman'\n",
      " 'freshman' 'man' 'mankind' 'manpower' 'boyfriend' 'husband' 'policeman'\n",
      " 'walter' 'brother' 'spokesman' 'upperclassman' 'gentleman' 'alumnus'\n",
      " 'alumni' 'man up' 'Mr.' 'man-made' 'the common man' 'mailman' 'steward'\n",
      " 'actor' 'congressman' 'acts as a leader' 'aggressive' 'ambitious'\n",
      " 'analytical' 'assertive' 'athletic' 'competitive' 'defends own beliefs'\n",
      " 'forceful' 'has leadership abilities' 'independent' 'individualistic'\n",
      " 'makes decisions easily']\n"
     ]
    }
   ],
   "source": [
    "print(male_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7388b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affectionate' 'child' 'cheer' 'commit' 'communal' 'compassion' 'connect'\n",
      " 'considerate' 'cooperat' 'depend' 'emotiona' 'empath' 'feminine'\n",
      " 'flatterable' 'gentle' 'honest' 'interpersonal' 'interdependen'\n",
      " 'interpersona' 'kind' 'kinship' 'loyal' 'modesty' 'nag' 'nurtur'\n",
      " 'pleasant' 'polite' 'quiet' 'respon' 'sensitiv' 'submissive' 'support'\n",
      " 'sympath' 'tender' 'together' 'trust' 'understand' 'warm' 'whin' 'yield'\n",
      " 'daughter' 'wife' 'girlfriend' 'waitress' 'sister' 'ladies' 'alumna'\n",
      " 'alumnae' 'hysterical' 'shrill' 'nagging' 'Mrs.' 'Miss.' 'Ms.'\n",
      " 'stewardess' 'actress']\n"
     ]
    }
   ],
   "source": [
    "print(female_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd6c27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start to test for checking male and female worsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56def600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bec6b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'sentences': ['Must be an extrovert with an innate quality of easily connecting with people.', \n",
    "                      'You are self-motivated and decisive, but willing to make changes with minimal grumbling when the client demands it.', \n",
    "                      'We are looking for a young and driven candidate who can bring innovation into the organization.']}\n",
    "\n",
    "df_test_sentence = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de0d9e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Must be an extrovert with an innate quality of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are self-motivated and decisive, but willi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are looking for a young and driven candidat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences\n",
       "0  Must be an extrovert with an innate quality of...\n",
       "1  You are self-motivated and decisive, but willi...\n",
       "2  We are looking for a young and driven candidat..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51fac07",
   "metadata": {},
   "source": [
    "## The following block is to find out in each sentence if there is any male or female words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2ca4117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 sentences have been processed.\n",
      "2 sentences have been processed.\n",
      "3 sentences have been processed.\n"
     ]
    }
   ],
   "source": [
    "df_check_result = pd.DataFrame()\n",
    "\n",
    "for index, sentence in df_test_sentence.iterrows():\n",
    "    temp_sentence = sentence['sentences']\n",
    "    tokenized_sentence = clean(temp_sentence)\n",
    "    \n",
    "    # there will be columns named 'category', 'word_in_sentences', and 'biased_term' in 'df_check_result' \n",
    "    category = 'neutral' \n",
    "    word_in_sentence = 'None' # \n",
    "    word = 'None' # \n",
    "    \n",
    "    # check for male words, and them put the outcome to \n",
    "    for male_word in male_words:\n",
    "        if re.search(r\"\\b{}\\b\".format(male_word), temp_sentence.lower().strip()): # search for 'male_word' in 'temp_sentence' using RE\n",
    "            # set output if 'male_word' is found\n",
    "            category = 'masculine'\n",
    "            word_in_sentence = male_word\n",
    "            word = male_word\n",
    "            #when there is no male word in the temp_sentence \n",
    "        else:\n",
    "            for token in tokenized_sentence:\n",
    "                if len(male_word) > 3:\n",
    "                    if simple_clean(male_word) == token[:len(male_word)]: # check if the male_word is found at the beginning of the token\n",
    "                        category = 'masculine'\n",
    "                        word_in_sentence = token\n",
    "                        word = male_word\n",
    "                    elif simple_clean(male_word) == token[-len(male_word):]: # check if the male_word is found at the end of the token\n",
    "                        category = 'masculine'\n",
    "                        word_in_sentence = token\n",
    "                        word = male_word\n",
    "            \n",
    "    if category == 'masculine': # put the outcome in a dict, then append them to 'df_check_result'\n",
    "        dict = {'sentence': temp_sentence,\n",
    "                'word_in_Sentence': word_in_sentence,\n",
    "                'biased_term': word,\n",
    "                'category': category\n",
    "               }\n",
    "        #df_check_result = df_check_result.append(dict, ignore_index = True)\n",
    "        df_check_result = pd.concat([df_check_result, pd.DataFrame([dict])], ignore_index=True)\n",
    "\n",
    "        \n",
    "        \n",
    "    # the completely same process for checking for female words\n",
    "    for female_word in female_words:\n",
    "        if re.search(r\"\\b{}\\b\".format(female_word), temp_sentence.lower().strip()):\n",
    "            category = 'feminine'\n",
    "            word_in_sentence = female_word\n",
    "            word = female_word\n",
    "        else:\n",
    "            for token in tokenized_sentence:\n",
    "                if len(female_word) > 3:\n",
    "                    if simple_clean(female_word) == token[:len(female_word)]:\n",
    "                        category = 'feminine'\n",
    "                        word_in_sentence = token\n",
    "                        word = female_word\n",
    "                    elif simple_clean(female_word) == token[-len(female_word):]:\n",
    "                        category = 'feminine'\n",
    "                        word_in_sentence = token\n",
    "                        word = female_word\n",
    "                    \n",
    "    if category == 'feminine':\n",
    "        dict = {'sentence': temp_sentence,\n",
    "                'word_in_Sentence': word_in_sentence,\n",
    "                'biased_term': word,\n",
    "                'category': category\n",
    "               }\n",
    "        #df_check_result = df_check_result.append(dict, ignore_index = True)\n",
    "        df_check_result = pd.concat([df_check_result, pd.DataFrame([dict])], ignore_index=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # This is to roughly monitor how many lines/sentences have been proceeded when running this block of code\n",
    "    #if index%10000 == 0:\n",
    "        #print(f'{index} sentences have been processed.' )\n",
    "        \n",
    "    print(f'{index + 1} sentences have been processed.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "765133f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_in_Sentence</th>\n",
       "      <th>biased_term</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Must be an extrovert with an innate quality of...</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "      <td>feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are self-motivated and decisive, but willi...</td>\n",
       "      <td>decisive</td>\n",
       "      <td>decisive</td>\n",
       "      <td>masculine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence word_in_Sentence  \\\n",
       "0  Must be an extrovert with an innate quality of...          connect   \n",
       "1  You are self-motivated and decisive, but willi...         decisive   \n",
       "\n",
       "  biased_term   category  \n",
       "0     connect   feminine  \n",
       "1    decisive  masculine  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the reult frome checking male/female words are now put into 'df_check_result'\n",
    "df_check_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6046b447",
   "metadata": {},
   "source": [
    "## This block is to find out male or female words in sentences as well, only to store outcomes in different form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6ee36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using df_jd_sentences to store sentences extracted from EMSCAD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68dbddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/09/j7wc58dn4n30y6z2hd4_3cch0000gn/T/ipykernel_47866/2752801453.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_jd_result = df_jd_result.append(dict, ignore_index = True)\n",
      "/var/folders/09/j7wc58dn4n30y6z2hd4_3cch0000gn/T/ipykernel_47866/2752801453.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_jd_result = df_jd_result.append(dict, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "df_jd_result = pd.DataFrame()\n",
    "\n",
    "for index, sentence in df_test_sentence.iterrows():\n",
    "    temp_sentence = sentence['sentences']\n",
    "    tokenized_sentence = clean(temp_sentence)\n",
    "    words_in_sentence = []\n",
    "    words = []\n",
    "    \n",
    "    if len(temp_sentence) < 180 and temp_sentence[0].isupper():\n",
    "        # check for male words\n",
    "        for male_word in male_words:\n",
    "            if re.search(r\"\\b{}\\b\".format(male_word), temp_sentence.lower().strip()):\n",
    "                words_in_sentence.append([male_word, 'M'])\n",
    "                words.append([male_word, 'M'])\n",
    "            else:\n",
    "                for token in tokenized_sentence:\n",
    "                    if len(male_word) > 3:\n",
    "                        if simple_clean(male_word) == token[:len(male_word)]:\n",
    "                            words_in_sentence.append([token, 'M'])\n",
    "                            words.append([male_word, 'M'])\n",
    "                        elif simple_clean(male_word) == token[-len(male_word):]:\n",
    "                            if token[:len(male_word)] != token[-len(male_word):]:\n",
    "                                words_in_sentence.append([token, 'M'])\n",
    "                                words.append([male_word, 'M'])\n",
    "\n",
    "        # check for female words\n",
    "        for female_word in female_words:\n",
    "            if re.search(r\"\\b{}\\b\".format(female_word), temp_sentence.lower().strip()):\n",
    "                words_in_sentence.append([female_word, 'F'])\n",
    "                words.append([male_word, 'F'])\n",
    "            else:\n",
    "                for token in tokenized_sentence:\n",
    "                    if len(female_word) > 3:\n",
    "                        if simple_clean(female_word) == token[:len(female_word)]:\n",
    "                            words_in_sentence.append([token, 'F'])\n",
    "                            words.append([female_word, 'F'])\n",
    "                        elif simple_clean(female_word) == token[-len(female_word):]:\n",
    "                            if token[:len(female_word)] != token[-len(female_word):]:\n",
    "                                words_in_sentence.append([token, 'F'])\n",
    "                                words.append([female_word, 'F'])\n",
    "\n",
    "        if len(words) > 0:\n",
    "            dict = {'sentence': temp_sentence,\n",
    "                    'word_in_Sentence': words_in_sentence,\n",
    "                    'biased_term': words}\n",
    "            df_jd_result = df_jd_result.append(dict, ignore_index = True)\n",
    "\n",
    "        if index%10000 == 0:\n",
    "            print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8545abac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_in_Sentence</th>\n",
       "      <th>biased_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Must be an extrovert with an innate quality of...</td>\n",
       "      <td>[[connect, F]]</td>\n",
       "      <td>[[connect, F]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are self-motivated and decisive, but willi...</td>\n",
       "      <td>[[decisive, M]]</td>\n",
       "      <td>[[decisive, M]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence word_in_Sentence  \\\n",
       "0  Must be an extrovert with an innate quality of...   [[connect, F]]   \n",
       "1  You are self-motivated and decisive, but willi...  [[decisive, M]]   \n",
       "\n",
       "       biased_term  \n",
       "0   [[connect, F]]  \n",
       "1  [[decisive, M]]  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23a77a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    temp = \" \".join(sentence.split())\n",
    "    temp = temp.strip()\n",
    "\n",
    "    char_to_remove = 0\n",
    "    for x in temp.split()[0]:\n",
    "        if not x.isalpha():\n",
    "            char_to_remove += 1\n",
    "    temp = temp[char_to_remove: len(temp) - char_to_remove]\n",
    "    return sentence\n",
    "\n",
    "'''\n",
    "In Pandas, the map() method is used to apply a function to every element of a Series object\n",
    "or a column of a DataFrame object. The map() method takes a function as an argument and applies\n",
    "it to each element of the Series or column, returning a new Series or column with the results of\n",
    "the function applied to each element.\n",
    "'''\n",
    "\n",
    "#cleaning the values in the 'sentence' column of 'df_new' using the 'clean_sentence' function\n",
    "df_jd_result['sentence'] = df_jd_result.sentence.map(lambda x:clean_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b26e742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_in_Sentence</th>\n",
       "      <th>biased_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Must be an extrovert with an innate quality of...</td>\n",
       "      <td>[[connect, F]]</td>\n",
       "      <td>[[connect, F]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are self-motivated and decisive, but willi...</td>\n",
       "      <td>[[decisive, M]]</td>\n",
       "      <td>[[decisive, M]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence word_in_Sentence  \\\n",
       "0  Must be an extrovert with an innate quality of...   [[connect, F]]   \n",
       "1  You are self-motivated and decisive, but willi...  [[decisive, M]]   \n",
       "\n",
       "       biased_term  \n",
       "0   [[connect, F]]  \n",
       "1  [[decisive, M]]  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jd_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa07770",
   "metadata": {},
   "source": [
    "### explore filtered sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b286d3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[connect, F]]     1\n",
       "[[decisive, M]]    1\n",
       "Name: biased_term, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jd_result.biased_term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9869248f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jd_result.biased_term.value_counts().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa5c2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found_words = []\n",
    "found_words = df_new.biased_term.value_counts().keys()\n",
    "for word in list(male_words) + list(female_words):  # frome the male/female words list\n",
    "    if word not in found_words:\n",
    "        not_found_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "26fcfdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['active', 'adventurous', 'aggress', 'ambitio', 'analy', 'assert', 'athlet', 'autonom', 'boast', 'challeng', 'compet', 'confident', 'courag', 'decide', 'decisive', 'decision', 'determin', 'dominant', 'domina', 'force', 'greedy', 'headstrong', 'hierarch', 'hostil', 'implusive', 'independen', 'individual', 'intellect', 'lead', 'logic', 'masculine', 'objective', 'opinion', 'outspoken', 'persist', 'principle', 'reckless', 'stubborn', 'superior', 'self-confiden', 'self-sufficien', 'self-relian', 'manmade', 'chairman', 'son', 'fireman', 'freshman', 'man', 'mankind', 'manpower', 'boyfriend', 'husband', 'policeman', 'walter', 'brother', 'spokesman', 'upperclassman', 'gentleman', 'alumnus', 'alumni', 'man up', 'Mr.', 'man-made', 'the common man', 'mailman', 'steward', 'actor', 'congressman', 'acts as a leader', 'aggressive', 'ambitious', 'analytical', 'assertive', 'athletic', 'competitive', 'defends own beliefs', 'forceful', 'has leadership abilities', 'independent', 'individualistic', 'makes decisions easily', 'affectionate', 'child', 'cheer', 'commit', 'communal', 'compassion', 'connect', 'considerate', 'cooperat', 'depend', 'emotiona', 'empath', 'feminine', 'flatterable', 'gentle', 'honest', 'interpersonal', 'interdependen', 'interpersona', 'kind', 'kinship', 'loyal', 'modesty', 'nag', 'nurtur', 'pleasant', 'polite', 'quiet', 'respon', 'sensitiv', 'submissive', 'support', 'sympath', 'tender', 'together', 'trust', 'understand', 'warm', 'whin', 'yield', 'daughter', 'wife', 'girlfriend', 'waitress', 'sister', 'ladies', 'alumna', 'alumnae', 'hysterical', 'shrill', 'nagging', 'Mrs.', 'Miss.', 'Ms.', 'stewardess', 'actress']\n"
     ]
    }
   ],
   "source": [
    "len(not_found_words)\n",
    "print(not_found_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f1bfd",
   "metadata": {},
   "source": [
    "### save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "13293f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jd_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5b97aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a coloum named sor\n",
    "\n",
    "annotation = []\n",
    "\n",
    "for index, row in df_jd_result.iterrows():\n",
    "    annotation.append(row[1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ea72839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['connect', 'decisive']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "162035d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jd_result['annotation'] = annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "480e7302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_in_Sentence</th>\n",
       "      <th>biased_term</th>\n",
       "      <th>sort</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Must be an extrovert with an innate quality of...</td>\n",
       "      <td>[[connect, F]]</td>\n",
       "      <td>[[connect, F]]</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are self-motivated and decisive, but willi...</td>\n",
       "      <td>[[decisive, M]]</td>\n",
       "      <td>[[decisive, M]]</td>\n",
       "      <td>decisive</td>\n",
       "      <td>decisive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence word_in_Sentence  \\\n",
       "0  Must be an extrovert with an innate quality of...   [[connect, F]]   \n",
       "1  You are self-motivated and decisive, but willi...  [[decisive, M]]   \n",
       "\n",
       "       biased_term      sort annotation  \n",
       "0   [[connect, F]]   connect    connect  \n",
       "1  [[decisive, M]]  decisive   decisive  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f2fc1e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = np.array_split(df_jd_result, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c21c505a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_in_Sentence</th>\n",
       "      <th>biased_term</th>\n",
       "      <th>sort</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Must be an extrovert with an innate quality of...</td>\n",
       "      <td>[[connect, F]]</td>\n",
       "      <td>[[connect, F]]</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence word_in_Sentence  \\\n",
       "0  Must be an extrovert with an innate quality of...   [[connect, F]]   \n",
       "\n",
       "      biased_term     sort annotation  \n",
       "0  [[connect, F]]  connect    connect  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d3fea2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_in_Sentence</th>\n",
       "      <th>biased_term</th>\n",
       "      <th>sort</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are self-motivated and decisive, but willi...</td>\n",
       "      <td>[[decisive, M]]</td>\n",
       "      <td>[[decisive, M]]</td>\n",
       "      <td>decisive</td>\n",
       "      <td>decisive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence word_in_Sentence  \\\n",
       "1  You are self-motivated and decisive, but willi...  [[decisive, M]]   \n",
       "\n",
       "       biased_term      sort annotation  \n",
       "1  [[decisive, M]]  decisive   decisive  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5dec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5bd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d7456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7478bd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f524d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
